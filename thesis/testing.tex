\chapter{Testing}
This chapter describes how testing is set up and managed a cross the applications and how \glsi{ci} is used.
The test setup is mainly a \gls{poc}, where we evaluate how the different frameworks supports testing and what implications are encountered during the process of setting it up and running the tests.
This knowledge is used to reflect on the framework choices made in the pre-studies, chapter \ref{ch:preStudy}.

The applications have limited business logic which results in code that benefits very little from testing and because of this, it is decided to spend as much time evaluating the framework choices instead of writing test for simple functionality.

\section{Front-end}
\Glsi{nativescript} have built in unit testing functionality to run tests on hardware or emulated devices \citep{testing:nativescript}.
When setting this up, there were, for now, an unfixable complication caused by the front-end application build configuration.
The project utilizes \glsi{webpack} to bundle and manipulate the source code at compile time and this is not compatible with the  unit testing flow of \glsi{nativescript}.

As of this, we decided to test the limited business logic of the application with a stand-alone testing framework running on \glsi{node}.
As \glsi{node} runs on the \glsi{v8} run-time, same as \textit{Android}, it still provides valid results though not running the tests on actual devices.

The business logic is only unit tested as integration tests are not possible without the \glsi{nativescript} testing framework.

\section{Back-end}
The back-end application is tested on two levels.
The first level is unit tests.
These are run on isolated functions where dependencies are mocked away.
The second level is integration tests.
These test the application on every level, with nothing mocked away. 

There are several web resources on unit testing and code coverage calculation for \glsi{node}.
But when using \gls{typescript} the coverage calculations should be made on the original source code, not the transpiled JavaScript, and this is not that straight forward.
But with research and \textit{trial and error} we came up with a solution that transpiles the \gls{typescript} test files on the fly and calculating coverage as well.
This works, but there still is an issue when calculating the complete coverage of the application.
Due to the build setup, the tool used to run tests can not read all files and there fore the coverage result is misleading.

\subsubsection{Unit tests}
Unit tests, test isolated parts of the application. 
They test functions at the different layers, where the below layer will be mocked away to make the tests isolated.
This is the simplest form of tests but are still a valuable tool to create a durable and well tested application.

\subsubsection{Integration tests}
Integration tests work differently than the unit tests. 
They do not test the code itself, but the application as a whole. 
This means that these tests only go well, if no errors occur in any layer of the application. 
A top-down approach is used \citep[pp. 662-669]{testing:integration}.
The integration tests start up the \glsi{node} server, and then starts querying against it's endpoints. 
When tests are run, a test database is used. This test database is seeded with known data every time the server starts in testing mode.

\subsubsection{Staging}
\label{sec:staging}
A staging environment is used to make sure that tests are run independently of the production environment. 
Two environment variables are important in this context.
\verb+NODE_ENV+ and \verb+ROM_DB_TEST+ are set on the \glsi{travis} server to make sure that the right things happen.

When \verb+NODE_ENV+ is set to \verb+test+, the database will be seeded upon server start.
That should only ever happen in a testing or developer environment and never in a production environment.

To avoid reseeds of the production database, two different environment variables are used.
When \verb+NODE_ENV+ is set to \verb+test+, the \verb+ROM_DB_TEST+ URL is used. 
When \verb+NODE_ENV+ is set to \verb+prod+, the \verb+ROM_DB_PROD+ URL is used. 
When running tests locally, \verb+NODE_ENV+ is automatically set to \verb+test+.
See chapter \ref{doc:ch:environmentVariables} in the documentation for details on the available environment variables.

If needed, the developer can run his code locally against the production database, but will never accidentally reseed the database.

\section{Continuous Integration}
A \glsi{travis} is set up to run builds, tests and more for both the front and back-end applications.

When commits are made and pushed to any one of the git repositories \glsi{travis} runs different tasks and verify the integrity of the commit.

What tasks to run is configured with a \verb+.travis.yml+ file in the root of the repository and includes:

\begin{enumerate}
\item \textbf{Linting}: Code style is tested to keep code quality high and consistent
\item \textbf{Build}: The source code is compiled
\item \textbf{Tests}: Unit tests, and integration tests on back-end, are run to test code functionality
\item \textbf{Code coverage}: Helps keeping track of what parts of the code is tested
\end{enumerate} 

Should any of these tasks fail, the user committing the code, will receive an email notification.
This helps both the developer who made the change, but also the developer that have to review the changes.

When a pull request is reviewed, it contains information about the test results and what the code coverage is.
If code coverage decreases in the pull request, compared to the master branch, then the developer probably did not test the code well enough. 
The lint check helps the reviewer to focus on the functional parts instead of syntactic and code style things.

\section{Conclusion}
On the back-end, the test setup became complicated as we used \gls{typescript}.
The final setup is not that complicated, but finding the right libraries and tools to get the job done proved more cumbersome than expected.
There is still an issue with the total coverage calculation that should be solved.

On the front-end, the test setup was, at first glance, easy to set up, but in the process we found out that this was actually not the case.
Due to this we had to make a choice if we wanted no tests at all or some representative tests to test core logic.
We decided on the latter and replicated the back-end testing setup.
This is working all right, but testing the source code on actual devices are preferred, especially when the JavaScript run-times differ between \textit{iOS} and \textit{Android}.

Enabling \glsi{ci} was one of the easiest task in the setup.
The \glsi{travis} service integrates with \glsi{github} and was literally activated with just a few clicks on their website.
The special needs for installing \textit{Android} \glspl{sdk}, to build the front-end, were setup by studying \glsi{nativescript} sample repositories \citep{testing:nativescript:sample}.
